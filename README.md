# awesome4me (Paper and Code)

### Image to Image Translation

#### 2023
- <a href='https://arxiv.org/abs/2303.08622'>Zero-Shot Contrastive loss for Text guided diffusion image style transfer</a>
[<a href='https://github.com/ZeConloss/ZeCon/tree/main/guided_diffusion'>code</a>]

#### 2022
- <a href='https://openaccess.thecvf.com/content/CVPR2022/papers/Tumanyan_Splicing_ViT_Features_for_Semantic_Appearance_Transfer_CVPR_2022_paper.pdf'>Splicing ViT Features of Semantic Apperance Transfer</a>
- <a href='https://arxiv.org/pdf/2301.04685v1.pdf'>SHUNIT: Style Harmonization for Unpaired Image-to-Image Translation</a>
- <a href='https://arxiv.org/pdf/2210.05559.pdf'>Unifying Diffusion Modelâ€™ Latent Space, With Aapplications to Cyclediffusion and guidance</a>
- <a href='https://arxiv.org/abs/2209.15264'>Diffusion-based Image Translation using Disentangled Style and Content Representation</a>

### Image Synthesis
#### 2023
- <a href='https://arxiv.org/pdf/2304.09728'>Any-to-Any Style Transfer: Making Picasso and Da Vinci Collaborate</a>
- <a href='https://arxiv.org/abs/2302.10167'>Cross-domain Compositing with Pretrained Diffusion Models</a>
#### 2022
- <a href='https://arxiv.org/abs/2111.14818'>Blended Diffusion for Text-driven Editing of Natural Images</a>
#### 2021
- <a href='https://arxiv.org/pdf/2108.03647'>AdaAttN: Revisit Attention Mechanism in Arbitrary Neural Style Transfer</a>

### Robust Model (Augmentation, Domain shift, etc..)
#### 2023
- <a href='https://arxiv.org/pdf/2304.08466.pdf'>Synthetic Data from Diffusion Models Improves ImageNet Classification</a>

#### 2022
- <a href='https://arxiv.org/abs/2209.07522'>Test-Time Training with Masked Autoencoders</a>
#### 2019
- <a href='https://arxiv.org/abs/1907.07484'>Benchmarking Robustness in Object Detection: Autonomous Driving when winter is coming</a>

### Augmentation with generative image
#### 2023
- <a href='https://arxiv.org/abs/2302.07944?fbclid=IwAR296TpG-ehDiTXyWFIIrxcrRFlVyA1Xt6zHyftWqgCrSfxb0_-izsZ-kAE'>Effective Data Augmentation with Diffusion Models</a>

#### 2018
- <a href='https://arxiv.org/abs/1810.10863'>GAN Augmentation: Augmenting Training Data using Generative Adversarial Networks</a>

### Sign Language

#### 2022
- <a href='https://openaccess.thecvf.com/content/CVPR2022/papers/Yin_MLSLT_Towards_Multilingual_Sign_Language_Translation_CVPR_2022_paper.pdf'>MLSLT: Towards Multilingual Sign Language Translation
</a>

### CLIP code

- <a href='https://github.com/openai/CLIP/tree/a9b1bf5920416aaeaec965c25dd9e8f98c864f16/clip'>CLIP</a> (Official)
- <a href='https://github.com/kuai-lab/sound-guided-semantic-image-manipulation/blob/main/soundclip/train.py'>CLIP Training</a> (not official but easy reference code)
- <a href='https://github.com/mlfoundations/open_clip'>Open CLIP</a> (semi official)
